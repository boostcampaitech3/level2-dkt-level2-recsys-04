{"cells":[{"cell_type":"markdown","metadata":{"id":"yt7sDAqHhfQp"},"source":["# OOF Stacking 베이스라인 \n","* (LGBM + XGBOOST + CATBOOST)"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.375544Z","start_time":"2021-05-24T09:49:28.999092Z"},"id":"Uq_TJqbdhfQu"},"outputs":[],"source":["import pandas as pd\n","import os\n","import random\n","import numpy as np\n","\n","import lightgbm as lgb\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"QZlm5HSmhfQv"},"source":["## 1. 데이터 로딩"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.678737Z","start_time":"2021-05-24T09:49:29.376581Z"},"id":"s6qgJ8MLhfQw"},"outputs":[],"source":["data_dir = '/opt/ml/input/data' # 경로는 상황에 맞춰서 수정해주세요!\n","\n","dtype = {\n","    'userID': 'int16',\n","    'answerCode': 'int8',\n","    'KnowledgeTag': 'int16'\n","} \n","\n","csv_file_path = os.path.join(data_dir, 'train_data.csv') # 데이터는 대회홈페이지에서 받아주세요 :)\n","df = pd.read_csv(csv_file_path, dtype=dtype, parse_dates=['Timestamp']) \n","\n","df = df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Feature Engineering"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from feature_engineering import FeatureEngineering\n","\n","class FeatCog(FeatureEngineering):\n","    def __init__(self, df):\n","        super(FeatCog, self).__init__()\n","        self.df = df\n","\n","    def __preprocessing__(self, df_past):\n","        self.df.sort_values(by=[\"userID\", \"Timestamp\"], inplace=True)        \n","\n","        # Test-Related\n","        self.df[\"test_L\"] = self.df[\"assessmentItemID\"].apply(lambda x: int(x[2]))\n","        self.df[\"test_M\"] = self.df[\"assessmentItemID\"].apply(lambda x: int(x[4:7]))\n","        self.df[\"test_S\"] = self.df[\"assessmentItemID\"].apply(lambda x: int(x[-3:]))\n","\n","        correct_t = self.df.groupby([\"testId\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n","        correct_t.columns = [\"test_mean\", \"test_sum\"]\n","        correct_k = self.df.groupby([\"KnowledgeTag\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n","        correct_k.columns = [\"tag_mean\", \"tag_sum\"]\n","\n","        self.df = pd.merge(self.df, correct_t, on=[\"testId\"], how=\"left\")\n","        self.df = pd.merge(self.df, correct_k, on=[\"KnowledgeTag\"], how=\"left\")\n","        \n","\n","        # User-Related\n","        self.df[\"user_correct_answer\"] = self.df.groupby(\"userID\")[\"answerCode\"].transform(lambda x: x.cumsum().shift(1))\n","        self.df[\"user_total_answer\"] = self.df.groupby(\"userID\")[\"answerCode\"].cumcount()\n","        self.df[\"user_acc\"] = self.df[\"user_correct_answer\"] / self.df[\"user_total_answer\"]\n","\n","\n","        # Tag-Related\n","        knowledge_clustered = self.df.loc[:, ['userID', 'KnowledgeTag']].groupby('userID').rolling(window=4, closed='right').std()\n","        self.df['knowledge_clustered'] = knowledge_clustered.values\n","        self.df['knowledge_clustered'] = self.df.knowledge_clustered.fillna(method='bfill')\n","        self.df['knowledge_clustered'][self.df.knowledge_clustered > 100] = 100 \n","\n","\n","        # Time-Related\n","        self.df[\"month\"] = self.df[\"Timestamp\"].dt.month\n","        self.df['week'] = self.df['Timestamp'].dt.isocalendar().week\n","        self.df[\"hour\"] = self.df[\"Timestamp\"].dt.hour\n","\n","        diff = self.df.loc[:, ['userID', 'Timestamp']].groupby('userID').diff().fillna(pd.Timedelta(seconds=0))\n","        diff = diff.fillna(pd.Timedelta(seconds=0))\n","        diff = diff['Timestamp'].apply(lambda x: x.total_seconds())\n","        self.df['duration'] = diff.values\n","        mean_duration = diff[(diff <= 135) & (diff >= 0)].mean()\n","        # criterion: quantile (75%) or NA => mean duration\n","        self.df['duration'] = self.df.duration.apply(lambda x: x if x <= 135 else mean_duration)\n","        self.df['duration'] = self.df.duration.apply(lambda x: x if x > 0 else mean_duration)\n","\n","\n","        # Past_history-Related\n","        self.df[[f'past_testid_{i}' for i in range(1, 6)]] = df_past[[f'past_testid_{i}' for i in range(1, 6)]]\n","        ans = df.loc[:, ['userID', 'answerCode']].groupby('userID').rolling(window=4, closed='left').mean()\n","        self.df['past_OX'] = ans.values\n","        self.df['past_OX'] = self.df.past_OX.fillna(method='bfill')\n","        \n","\n","        # Drop null values (user_correct_answer, user_acc)\n","        self.df = self.df.dropna()\n","        return self.df"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df_past = pd.read_csv('train_past_tID.csv')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_32021/2255738000.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self.df['knowledge_clustered'][self.df.knowledge_clustered > 100] = 100\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>userID</th>\n","      <th>assessmentItemID</th>\n","      <th>testId</th>\n","      <th>answerCode</th>\n","      <th>Timestamp</th>\n","      <th>KnowledgeTag</th>\n","      <th>test_L</th>\n","      <th>test_M</th>\n","      <th>test_S</th>\n","      <th>test_mean</th>\n","      <th>...</th>\n","      <th>month</th>\n","      <th>week</th>\n","      <th>hour</th>\n","      <th>duration</th>\n","      <th>past_testid_1</th>\n","      <th>past_testid_2</th>\n","      <th>past_testid_3</th>\n","      <th>past_testid_4</th>\n","      <th>past_testid_5</th>\n","      <th>past_OX</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>A060001002</td>\n","      <td>A060000001</td>\n","      <td>1</td>\n","      <td>2020-03-24 00:17:14</td>\n","      <td>7225</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0.947683</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>3.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>A060001003</td>\n","      <td>A060000001</td>\n","      <td>1</td>\n","      <td>2020-03-24 00:17:22</td>\n","      <td>7225</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0.947683</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>8.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>A060001004</td>\n","      <td>A060000001</td>\n","      <td>1</td>\n","      <td>2020-03-24 00:17:29</td>\n","      <td>7225</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.947683</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>7.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>A060001005</td>\n","      <td>A060000001</td>\n","      <td>1</td>\n","      <td>2020-03-24 00:17:36</td>\n","      <td>7225</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0.947683</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>7.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>A060001007</td>\n","      <td>A060000001</td>\n","      <td>1</td>\n","      <td>2020-03-24 00:17:47</td>\n","      <td>7225</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>0.947683</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>11.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 27 columns</p>\n","</div>"],"text/plain":["   userID assessmentItemID      testId  answerCode           Timestamp  \\\n","1       0       A060001002  A060000001           1 2020-03-24 00:17:14   \n","2       0       A060001003  A060000001           1 2020-03-24 00:17:22   \n","3       0       A060001004  A060000001           1 2020-03-24 00:17:29   \n","4       0       A060001005  A060000001           1 2020-03-24 00:17:36   \n","5       0       A060001007  A060000001           1 2020-03-24 00:17:47   \n","\n","   KnowledgeTag  test_L  test_M  test_S  test_mean  ...  month  week  hour  \\\n","1          7225       6       1       2   0.947683  ...      3    13     0   \n","2          7225       6       1       3   0.947683  ...      3    13     0   \n","3          7225       6       1       4   0.947683  ...      3    13     0   \n","4          7225       6       1       5   0.947683  ...      3    13     0   \n","5          7225       6       1       7   0.947683  ...      3    13     0   \n","\n","   duration  past_testid_1  past_testid_2  past_testid_3  past_testid_4  \\\n","1       3.0             -1             -1             -1             -1   \n","2       8.0             -1             -1             -1             -1   \n","3       7.0             -1             -1             -1             -1   \n","4       7.0             -1             -1             -1             -1   \n","5      11.0             -1             -1             -1             -1   \n","\n","   past_testid_5  past_OX  \n","1             -1      1.0  \n","2             -1      1.0  \n","3             -1      1.0  \n","4             -1      1.0  \n","5             -1      1.0  \n","\n","[5 rows x 27 columns]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["fe = FeatCog(df)\n","df = fe(df_past = df_past)\n","df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n","       'KnowledgeTag', 'test_L', 'test_M', 'test_S', 'test_mean', 'test_sum',\n","       'tag_mean', 'tag_sum', 'user_correct_answer', 'user_total_answer',\n","       'user_acc', 'knowledge_clustered', 'month', 'week', 'hour', 'duration',\n","       'past_testid_1', 'past_testid_2', 'past_testid_3', 'past_testid_4',\n","       'past_testid_5', 'past_OX'],\n","      dtype='object')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cate = sum([['testId', 'assessmentItemID', 'KnowledgeTag', 'month', 'hour', 'week'],\n","            [f'past_testid_{i}' for i in range(1, 6)],\n","           ], [])\n","for c in cate:\n","    df[c] = df[c].astype('category')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.sample(10)"]},{"cell_type":"markdown","metadata":{"id":"5VZzei3DhfQy"},"source":["## 3. Train/Test 데이터 셋 분리"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.684739Z","start_time":"2021-05-24T09:49:28.982Z"},"id":"YOPWK7ckhfQz"},"outputs":[],"source":["# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n","random.seed(42)\n","############################################################ 0.7 #######################################################################\n","def custom_train_test_split(df, ratio=0.7, split=True):\n","    \n","    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n","    random.shuffle(users)\n","    \n","    max_train_data_len = ratio*len(df)\n","    sum_of_train_data = 0\n","    user_ids =[]\n","\n","    for user_id, count in users:\n","        sum_of_train_data += count\n","        if max_train_data_len < sum_of_train_data:\n","            break\n","        user_ids.append(user_id)\n","\n","\n","    train = df[df['userID'].isin(user_ids)]\n","    test = df[df['userID'].isin(user_ids) == False]\n","\n","    #test데이터셋은 각 유저의 마지막 interaction만 추출\n","    test = test[test['userID'] != test['userID'].shift(-1)]\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-24T09:49:29.686739Z","start_time":"2021-05-24T09:49:28.984Z"},"id":"i3HzdoybhfQ0"},"outputs":[],"source":["# 유저별 분리\n","train, test = custom_train_test_split(df)\n","\n","# 사용할 Feature 설정\n","FEATS = ['month', 'hour', 'week', 'past_OX', 'test_L', 'test_M', 'test_S', 'knowledge_clustered',\n","         'KnowledgeTag', 'user_correct_answer', 'user_total_answer', 'duration', 'testId',\n","         'user_acc', 'test_mean', 'test_sum', 'tag_mean','tag_sum',\n","         'assessmentItemID', 'past_testid_1', 'past_testid_2', 'past_testid_3', 'past_testid_4', 'past_testid_5']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.where(test.answerCode == -1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# drop outliers\n","# 1. # of items solved <= 30\n","# 2. 0.1 <= total score <= 0.95\n","\n","# total_solved = df.groupby('userID').agg({'assessmentItemID':'count'})\n","# total_score = df.groupby('userID').agg({'answerCode': 'mean'})\n","\n","# outlier_i = total_solved[total_solved.assessmentItemID <= 30].index\n","# outlier_a = total_score[(total_score.answerCode <= 0.1) | (total_score.answerCode >= 0.95)].index\n","# outlier = outlier_i.union(outlier_a)\n","\n","# train = train.drop(train[train.userID.isin(outlier)].index)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X, y 값 분리\n","y_train = train['answerCode']\n","train = train.drop(['answerCode'], axis=1)\n","\n","y_test = test['answerCode']\n","test = test.drop(['answerCode'], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["## OOF Stacking"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_absolute_error\n","\n","import lightgbm as lgb\n","import xgboost as xgb\n","import catboost as cb\n","\n","from matplotlib import pyplot as plt\n","import matplotlib"]},{"cell_type":"markdown","metadata":{},"source":["### LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = train[FEATS]\n","X_test  = test[FEATS]\n","# y_train = train['answerCode']\n","# y_test = test['answerCode']\n","\n","# Number of folds\n","n_folds = 4\n","# Empty array to store out-of-fold predictions (single column)\n","S_train_lgb = np.zeros((X_train.shape[0], 1))\n","# Empty array to store temporary test set predictions made in each fold\n","S_test_temp = np.zeros((X_test.shape[0], n_folds))\n","# Empty list to store scores from each fold\n","scores = []\n","# Split initialization\n","kf = KFold(n_splits=n_folds, shuffle=True, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Loop across folds\n","for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n","    \n","    # Split data and target\n","    X_tr = X_train.iloc[tr_index]\n","    y_tr = y_train.iloc[tr_index]\n","    X_te = X_train.iloc[te_index]\n","    y_te = y_train.iloc[te_index]\n","    \n","    # Fit\n","    lgb_train = lgb.Dataset(X_tr, y_tr)\n","    lgb_test  = lgb.Dataset(X_te, y_te)\n","    model = lgb.train(\n","        {'objective': 'binary',\n","        'metric': 'auc',\n","        'max_depth':8,\n","        'num_leaves':64,\n","        },  \n","        lgb_train,\n","        valid_sets=[lgb_train, lgb_test],\n","        verbose_eval=100,\n","        num_boost_round=500,\n","        early_stopping_rounds=100\n","    )\n","    \n","    # Predict out-of-fold part of train set\n","    S_train_lgb[te_index, :] = model.predict(X_te).reshape(-1, 1)\n","    \n","    # Predict test set\n","    S_test_temp[:, fold_counter] = model.predict(X_test)\n","    \n","    # Print score of current fold\n","    score = mean_absolute_error(y_te, S_train_lgb[te_index, :])\n","    scores.append(score)\n","    print('fold %d: [%.8f]' % (fold_counter, score))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = model.predict(test[FEATS])\n","acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n","auc = roc_auc_score(y_test, preds)\n","\n","print(f'VALID AUC : {auc} ACC : {acc}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compute mean of temporary test set predictions to get final test set prediction\n","S_test_lgb = np.mean(S_test_temp, axis=1).reshape(-1, 1)\n","\n","# Mean OOF score + std\n","print('\\nMEAN:   [%.8f] + [%.8f]' % (np.mean(scores), np.std(scores)))\n","\n","# Full OOF score\n","# !!! FULL score slightly differs from MEAN score because folds contain\n","# different number of examples (404 can't be divided by 3)\n","# If we set n_folds=4 scores will be identical for given metric\n","print('FULL:   [%.8f]' % (mean_absolute_error(y_train, S_train_lgb)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["zeros = np.where(y_test == 0)[0]\n","ones = np.where(y_test == 1)[0]\n","\n","fig, ax = plt.subplots(figsize=(12,8))\n","\n","ax.set_title('Distribution of predicted zeros and ones')\n","\n","ax.hist(S_test_lgb[zeros], bins=50, alpha=0.5, stacked=True, density=1, label='Zeros')\n","ax.hist(S_test_lgb[ones], bins=50, alpha=0.5, stacked=True, density=1, label='Ones')\n","\n","ax.legend()"]},{"cell_type":"markdown","metadata":{},"source":["### XGBoost"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgb.set_config(verbosity=0)\n","\n","# Empty array to store out-of-fold predictions (single column)\n","S_train_xgb = np.zeros((X_train.shape[0], 1))\n","# Empty array to store temporary test set predictions made in each fold\n","S_test_temp = np.zeros((X_test.shape[0], n_folds))\n","# Convert to XGBoost matrix\n","X_test_xgb = xgb.DMatrix(X_test, enable_categorical=True)\n","\n","params = {'learning_rate': 0.01,\n","            'max_depth':8,\n","            'eta' : 0.1,\n","            'objective': 'binary:logistic',\n","            'eval_metric': 'auc',\n","#           'is_training_metric': True,\n","            'feature_fraction': 1,\n","            'seed':42,\n","            'gpu_id':0\n","            }\n","# Loop across folds\n","for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n","    \n","    # Split data and target\n","    X_tr = X_train.iloc[tr_index]\n","    y_tr = y_train.iloc[tr_index]\n","    X_te = X_train.iloc[te_index]\n","    y_te = y_train.iloc[te_index]\n","    \n","    # Fit\n","    xgb_train = xgb.DMatrix(X_tr, y_tr, enable_categorical=True)\n","    xgb_test  = xgb.DMatrix(X_te, y_te, enable_categorical=True)\n","    model = xgb.train(\n","                    params, \n","                    xgb_train,\n","                    evals = [(xgb_train, 'train'), (xgb_test,'eval')],\n","                    num_boost_round=500,\n","                    early_stopping_rounds=100\n","                )\n","    \n","    # Predict out-of-fold part of train set\n","    S_train_xgb[te_index, :] = model.predict(xgb_test).reshape(-1, 1)\n","    \n","    # Predict test set\n","    S_test_temp[:, fold_counter] = model.predict(X_test_xgb)\n","    \n","    # Print score of current fold\n","    score = mean_absolute_error(y_te, S_train_xgb[te_index, :])\n","    scores.append(score)\n","    print('fold %d: [%.8f]' % (fold_counter, score))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = model.predict(X_test_xgb)\n","acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n","auc = roc_auc_score(y_test, preds)\n","\n","print(f'VALID AUC : {auc} ACC : {acc}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compute mean of temporary test set predictions to get final test set prediction\n","S_test_xgb = np.mean(S_test_temp, axis=1).reshape(-1, 1)\n","\n","# Mean OOF score + std\n","print('\\nMEAN:   [%.8f] + [%.8f]' % (np.mean(scores), np.std(scores)))\n","\n","# Full OOF score\n","# !!! FULL score slightly differs from MEAN score because folds contain\n","# different number of examples (404 can't be divided by 3)\n","# If we set n_folds=4 scores will be identical for given metric\n","print('FULL:   [%.8f]' % (mean_absolute_error(y_train, S_train_xgb)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["zeros_tr = np.where(y_train == 0)[0]\n","ones_tr = np.where(y_train == 1)[0]\n","\n","fig, ax = plt.subplots(figsize=(12,8))\n","\n","ax.set_xlabel('Predicted Probability')\n","ax.set_ylabel('Scaled Counts')\n","ax.set_title('Distribution of predicted zeros and ones (LGBM)')\n","\n","ax.hist(S_train_lgb[zeros_tr], bins=50, alpha=0.5, stacked=True, density=1, label='Zeros')\n","ax.hist(S_train_lgb[ones_tr], bins=50, alpha=0.5, stacked=True, density=1, label='Ones')\n","\n","ax.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, ax = plt.subplots(figsize=(12,8))\n","\n","ax.set_title('Distribution of predicted zeros and ones')\n","\n","ax.hist(S_test_xgb[zeros], bins=50, alpha=0.5, stacked=True, density=1, label='Zeros')\n","ax.hist(S_test_xgb[ones], bins=50, alpha=0.5, stacked=True, density=1, label='Ones')\n","\n","ax.legend()"]},{"cell_type":"markdown","metadata":{},"source":["### CatBoost"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pandas.api.types import is_numeric_dtype\n","\n","def get_categorical_indicies(X):\n","    cats = []\n","    for col in X.columns:\n","        if is_numeric_dtype(X[col]):\n","            pass\n","        else:\n","            cats.append(col)\n","    cat_indicies = []\n","    for col in cats:\n","        cat_indicies.append(X.columns.get_loc(col))\n","    return cat_indicies\n","\n","train_categorical_indicies = get_categorical_indicies(X_train)\n","test_categorical_indicies = get_categorical_indicies(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Empty array to store out-of-fold predictions (single column)\n","S_train_cat = np.zeros((X_train.shape[0], 1))\n","# Empty array to store temporary test set predictions made in each fold\n","S_test_temp = np.zeros((X_test.shape[0], n_folds))\n","# Convert to catvoost array\n","X_test_cat  = cb.Pool(X_test, cat_features=test_categorical_indicies)\n","\n","scores = []\n","\n","params = {'learning_rate': 0.01,\n","            'depth':8,\n","            'objective': 'Logloss',\n","            'eval_metric': 'AUC',\n","#           'is_training_metric': True,\n","            # 'seed':42,\n","            'task_type':\"GPU\",\n","            # 'devices':0\n","            }\n","# Loop across folds\n","for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n","    \n","    # Split data and target\n","    X_tr = X_train.iloc[tr_index]\n","    y_tr = y_train.iloc[tr_index]\n","    X_te = X_train.iloc[te_index]\n","    y_te = y_train.iloc[te_index]\n","    \n","    # Fit\n","    cat_train = cb.Pool(X_tr, y_tr, cat_features=train_categorical_indicies)\n","    cat_test  = cb.Pool(X_te, y_te, cat_features=train_categorical_indicies)\n","    model = cb.train(\n","                    params, \n","                    cat_train,\n","                    evals = [(cat_train, 'train'), (cat_test,'eval')],\n","                    num_boost_round=500,\n","                    early_stopping_rounds=100\n","                )\n","    \n","    # Predict out-of-fold part of train set\n","    S_train_cat[te_index, :] = model.predict(cat_test).reshape(-1, 1)\n","    \n","    # Predict test set\n","    S_test_temp[:, fold_counter] = model.predict(X_test_cat)\n","    \n","    # Print score of current fold\n","    score = mean_absolute_error(y_te, S_train_cat[te_index, :])\n","    scores.append(score)\n","    print('fold %d: [%.8f]' % (fold_counter, score))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["preds = model.predict(test[FEATS])\n","acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n","auc = roc_auc_score(y_test, preds)\n","\n","print(f'VALID AUC : {auc} ACC : {acc}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compute mean of temporary test set predictions to get final test set prediction\n","S_test_cat = np.mean(S_test_temp, axis=1).reshape(-1, 1)\n","\n","# Mean OOF score + std\n","print('\\nMEAN:   [%.8f] + [%.8f]' % (np.mean(scores), np.std(scores)))\n","\n","# Full OOF score\n","# !!! FULL score slightly differs from MEAN score because folds contain\n","# different number of examples (404 can't be divided by 3)\n","# If we set n_folds=4 scores will be identical for given metric\n","print('FULL:   [%.8f]' % (mean_absolute_error(y_train, S_train_cat)))"]},{"cell_type":"markdown","metadata":{},"source":["### Second Level Analysis (Ensemble)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["S_train = np.hstack([S_train_lgb, S_train_xgb, S_train_cat])\n","S_test = np.hstack([S_test_lgb, S_test_xgb, S_test_cat])\n","S_train.size"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert to LGBM dataset\n","lgb_train = lgb.Dataset(S_train, y_train)\n","lgb_test = lgb.Dataset(S_test, y_test)\n","\n","# Initialize and fit 2nd level model\n","model = lgb.train(\n","        {'objective': 'binary',\n","        'metric': 'auc',\n","        'max_depth':6,\n","        'num_leaves':16,\n","        },  \n","        lgb_train,\n","        valid_sets=[lgb_train, lgb_test],\n","        verbose_eval=100,\n","        num_boost_round=500,\n","        early_stopping_rounds=100\n","    )\n","\n","# Predict\n","y_pred = model.predict(S_test)\n","\n","# Final prediction score\n","from sklearn.metrics import log_loss\n","print('Final prediction score: %.8f' % log_loss(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["## Store Preprocessed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.save('S_train_lgb.npy', S_train_lgb)\n","np.save('S_test_lgb.npy', S_test_lgb)\n","np.save('S_train_xgb.npy', S_train_xgb)\n","np.save('S_test_xgb.npy', S_test_xgb)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ?????????????????????????????????????????????? #\n","train.to_csv('train_preprocessed.csv', sep=',')\n","test.to_csv('val_preprocessed.csv', sep=',')\n","# ?????????????????????????????????????????????? #"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"(미션-2) LGBM Baseline.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
